{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "In this section we load the dataset from the previously created parquet file. Then we preprocess it and slit it into train and test samples.\n",
    "\n",
    "A random Forest Classifier is trained on these samples and used to predict the quality of a given cell (good, bad)\n",
    "\n",
    "We then convert the sklearn model to hummingbird and observer performance differences in how fast the classifier is able to predict the cells labels.\n",
    "\n",
    "We again need the pyarrow libary to read the dataset.\n",
    "\n",
    "\n",
    "First we install hummingbird-ml via the terminal. The installation command goes as follows:\n",
    "\n",
    "pip install hummingbird-ml\n",
    "\n",
    "\n",
    "In order to convert a sklearn model to a different framework we utilize the convert function.\n",
    "\n",
    "convert accepts two parameter: convert(model, 'dnn_framework')\n",
    "\n",
    "For our test we convert the random forest model to pytorch.\n",
    "\n",
    "\n",
    "Lastly, we use some support functions that are located in utils. \n",
    "\n",
    " - split: for splitting the dataset into train and test sets\n",
    " - rf_grd_sr: for applying grid search \n",
    " - random_forest: for training a random forest model\n",
    " - test_clf: for testing our model\n",
    " - save_model: for saving our model to disk\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "from utils import split, rf_grd_sr, random_forest, test_clf, save_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to specfiy some parameters before we can start.\n",
    "\n",
    "DIR = the directory where our parquet files are located\n",
    "clf_dir = the directory where the trained model will be saved\n",
    "\n",
    "cases_to_train = a list of models which will be trained. Here we specify the name of the parquet dataset file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./dataset/\"\n",
    "clf_dir = \"./clf/\"\n",
    "\n",
    "cases_to_train = [\"cell_data_100000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what we have tested previously, we load the datasdet with pq.read_pandas and convert it in the same spot to a pandas dataframe. This can be done with .to_pandas()\n",
    "\n",
    "From the collection of feature we only want to remove the \"pro-STAR Cell Id\" feature.\n",
    "It is a unique ID and wont help us in classifying the quality of a given cell.\n",
    "\n",
    "\n",
    "Lastly, we split the dataset into train and test samples with a 70/30 split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Cases:  cell_data_100000\n",
      "\n",
      "***   Learning Pipeline Configuration:   ***\n",
      "\n",
      "Loading case: cell_data_100000 \n",
      "\n",
      "for training:\n",
      "    X_train_cell_data_100000, y_train_cell_data_100000\n",
      "\n",
      "for testing:\n",
      "    X_test_cell_data_100000, y_test_cell_data_100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_ds(dc,train,test):\n",
    "    for case in dc:\n",
    "        print(\"Loading case:\", case, \"\\n\")\n",
    "        \n",
    "        ## read the dataset from distk and convert it to a pandas dataframe\n",
    "        ds = pq.read_pandas(DIR + case +'_arrow.parquet').to_pandas()\n",
    "\n",
    "        ## delete an unnecessary feature\n",
    "        del ds[\"pro-STAR Cell Id\"]\n",
    "\n",
    "        ## split into train and test samples\n",
    "        train[\"X_train_\" + case], test[\"X_test_\" + case], train[\"y_train_\" + case], test[\"y_test_\" + case] = split(ds, case)\n",
    "\n",
    "print(\"Selected Cases: \", ', '.join([c for c in cases_to_train]))\n",
    "print(\"\\n***   Learning Pipeline Configuration:   ***\\n\")\n",
    "\n",
    "train = {}\n",
    "test = {}\n",
    "\n",
    "load_ds(cases_to_train, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with the training of our Random Forest classifier, it is adviceable to apply a GridSearchCV operation to identify the best hyperparameter setting.\n",
    "\n",
    "This process can be a very time consuming operation, depending on the specified gird_params. For the purpose of this project, I have already run this process, but feel free to rerun this step on your machine.\n",
    "\n",
    "The estimated best parameters for our Random Forest Classifier are:\n",
    "\n",
    "clf  = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_features=\"auto\", min_samples_split=2, min_impurity_decrease=0.0, random_state=42, n_jobs=jobs)\n",
    "\n",
    "If apply_optimization is set to False we skip the whole GridSearch process and apply the identified best params. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest: cell_data_100000\n",
      "Learning duration: 4.273419380187988\n"
     ]
    }
   ],
   "source": [
    "apply_optimization = False # apply grid search optimization?\n",
    "\n",
    "####### Random Forests ######\n",
    "def train_rf(case):\n",
    "    \n",
    "    ## apply grid search optimization\n",
    "    if apply_optimization:\n",
    "        best_params = rf_grd_sr(train[\"X_train_\" + case], train[\"y_train_\" + case], \"rf_\"+case)\n",
    "    else:\n",
    "        best_params = False\n",
    "\n",
    "    ## train the classifier\n",
    "    print(\"Training Random Forest:\", case)\n",
    "    clf = random_forest(train[\"X_train_\" + case], train[\"y_train_\" + case], -1, best_params)\n",
    "    \n",
    "    ## save the model\n",
    "    save_model(clf, \"clf_rf_\" + case, clf_dir, len(train[\"X_train_\" + case].columns))\n",
    "       \n",
    "    return clf\n",
    "\n",
    "\n",
    "for case in cases_to_train:\n",
    "    clf = train_rf(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the performance of our model we trigger test_clf and pass the model and test data.\n",
    "\n",
    "The performance of the model looks great. We just have a few misclassifications, shown by the confusion matrix. Consequently precision and recall are both high.\n",
    "\n",
    "But for this test we are interested in the time duration the model needs to predict these 30k samples.\n",
    "\n",
    "Our benchmark is thus; 0.71 seconds for processing 30k samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: clf_rf_cell_data_100000\n",
      "\n",
      "Predicting duration: 0.08911323547363281\n",
      "Accuracy 0.9973334222192594\n",
      "Confusion Matrix\n",
      "[[14985    12]\n",
      " [   68 14936]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14997\n",
      "           1       1.00      1.00      1.00     15004\n",
      "\n",
      "    accuracy                           1.00     30001\n",
      "   macro avg       1.00      1.00      1.00     30001\n",
      "weighted avg       1.00      1.00      1.00     30001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_clf(clf, \"clf_rf_\" + case, test[\"X_test_\" + case].to_numpy(),test[\"y_test_\" + case])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use hummingbird to convert our sklearn Random Forest Model to PyTorch. First we test with a CPU based version and later with a GPU based version.\n",
    "\n",
    "To convert a model to pyTorch we use the convert function provided by Hummingbird and specify the model we want to convert, the target Framework, and the device properties.\n",
    "\n",
    "After converting the model we again test the model via the same test_pipeline and mesure the time performance of 30k predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hummingbird to convert the model to PyTorch\n",
    "pytorch_model = convert(clf, 'pytorch', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: clf_rf_cell_data_100000\n",
      "\n",
      "Predicting duration: 1.4146027565002441\n",
      "Accuracy 0.9973334222192594\n",
      "Confusion Matrix\n",
      "[[14985    12]\n",
      " [   68 14936]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14997\n",
      "           1       1.00      1.00      1.00     15004\n",
      "\n",
      "    accuracy                           1.00     30001\n",
      "   macro avg       1.00      1.00      1.00     30001\n",
      "weighted avg       1.00      1.00      1.00     30001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_clf(pytorch_model, \"clf_rf_\" + case, test[\"X_test_\" + case].to_numpy(),test[\"y_test_\" + case])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test the GPU version of our Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hummingbird to convert the model to PyTorch\n",
    "pytorch_model_cuda = convert(clf, 'pytorch', device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required time is now 0.43 seconds for 30k samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: clf_rf_cell_data_100000\n",
      "\n",
      "Predicting duration: 0.05672001838684082\n",
      "Accuracy 0.9973334222192594\n",
      "Confusion Matrix\n",
      "[[14985    12]\n",
      " [   68 14936]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14997\n",
      "           1       1.00      1.00      1.00     15004\n",
      "\n",
      "    accuracy                           1.00     30001\n",
      "   macro avg       1.00      1.00      1.00     30001\n",
      "weighted avg       1.00      1.00      1.00     30001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_clf(pytorch_model_cuda, \"clf_rf_\" + case, test[\"X_test_\" + case].to_numpy(),test[\"y_test_\" + case])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
